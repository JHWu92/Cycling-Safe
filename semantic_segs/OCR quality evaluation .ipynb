{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TXT_OCR_NAS_DIR = 'data/boxes/TXT_OCR_NAS/'\n",
    "TXT_CROWDSOURCE_DIR = 'data/boxes/TXT_Crowdsource/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bugs solved:\n",
    "1. I found that in some cases, case sensitive has larger similarity than case insensitive. the problem is solved by setting autojunk=False. Altough I still have no idea why using lower() will trigger auto junk while origin text doesn't. http://stackoverflow.com/questions/12142339/unexplaned-behavior-with-difflib-sequencematcher-get-matching-blocks\n",
    "\n",
    "# potential bugs:\n",
    "1. character \\xc2\\x95 is found in 'Box8-MINIDOKA to TULE LAKE-0269.txt' and 'Box8-MINIDOKA to TULE LAKE-0272', both in crowdsource and ocr nas. Not sure how many times does this happen. We can simply remove them, but it might have something to do with encoding. But I just leave them there by now(http://stackoverflow.com/questions/6609895/efficiently-replace-bad-characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import difflib\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_file_path(gt_dir, ocr_dir):\n",
    "    gt_paths = list(glob.glob(gt_dir+'*/*.txt'))\n",
    "    ocr_paths = list(glob.glob(ocr_dir+'*/*.txt'))\n",
    "    return gt_paths, ocr_paths\n",
    "\n",
    "def get_file_names(gt_paths, ocr_paths):\n",
    "    gt_fns = [path.rsplit('\\\\',1)[-1] for path in gt_paths]\n",
    "    ocr_fns = [path.rsplit('\\\\',1)[-1] for path in ocr_paths]\n",
    "    assert len(set(ocr_fns)) == len(ocr_fns), 'you get duplicate file names in ocr files'\n",
    "    assert len(set(gt_fns)) == len(gt_fns), 'you get duplicate file names in gt files'\n",
    "    assert set(ocr_fns).issubset(set(gt_fns)), 'ocr file names to be tested are not a subset of ground truth dataset'\n",
    "    return gt_fns, ocr_fns\n",
    "\n",
    "\n",
    "def pair_paths(gt_paths, ocr_paths, gt_fns, ocr_fns):\n",
    "    gt_df = pd.DataFrame(zip(gt_paths, gt_fns), columns=['gt_path','fn'])\n",
    "    ocr_df = pd.DataFrame(zip(ocr_paths, ocr_fns), columns=['ocr_path', 'fn'])\n",
    "    paired_df = ocr_df.merge(gt_df)\n",
    "    paired_df = paired_df[['fn', 'gt_path', 'ocr_path']]\n",
    "    return paired_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_similarity('abcdefghijk ','abdejk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_diff(seq1, seq2):\n",
    "    d = difflib.Differ()\n",
    "    diff = d.compare(seq1, seq2)\n",
    "    return diff\n",
    "\n",
    "def get_diff_str(seq1, seq2):\n",
    "    return ' '.join(get_diff(seq1, seq2))\n",
    "    \n",
    "def cal_similarity(seq1, seq2):\n",
    "    return difflib.SequenceMatcher(a=seq1, b=seq2, autojunk=False).ratio()\n",
    "\n",
    "def char_similarity(seq1, seq2, case_sensitive=False):\n",
    "    assert type(seq1)==str, 'seq1 is not a string'\n",
    "    assert type(seq2)==str, 'seq2 is not a string'\n",
    "    if not case_sensitive:\n",
    "        seq1, seq2 = seq1.lower(), seq2.lower()\n",
    "    return cal_similarity(seq1, seq2)\n",
    "\n",
    "def wordize(s):\n",
    "    return re.split('[ \\n]', s)\n",
    "\n",
    "\n",
    "def word_similarity(seq1, seq2, case_sensitive=False):\n",
    "    assert type(seq1)==str, 'seq1 is not a string'\n",
    "    assert type(seq2)==str, 'seq2 is not a string'\n",
    "    if not case_sensitive:\n",
    "        seq1, seq2 = seq1.lower(), seq2.lower()\n",
    "    return cal_similarity(wordize(seq1), wordize(seq2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "248\n"
     ]
    }
   ],
   "source": [
    "CNT_OCR_CLEAN = 0 \n",
    "def ocr_nas_remove_page(ocr_lines):\n",
    "    global CNT_OCR_CLEAN\n",
    "    if '----Page 1----' in ocr_lines[0]:\n",
    "        CNT_OCR_CLEAN+=1\n",
    "        return ocr_lines[1:]\n",
    "    return ocr_lines\n",
    "def replace_consecutive_space(s):\n",
    "    return ' '.join(re.split(' +', s))\n",
    "\n",
    "def refine_lines(lines):\n",
    "    new_lines = []\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if line:\n",
    "            line = replace_consecutive_space(line)\n",
    "            new_lines.append(line)\n",
    "    return '\\n'.join(new_lines)\n",
    "        \n",
    "\n",
    "def get_str(gt_path, ocr_path):\n",
    "    gt_lines = open(gt_path).readlines()\n",
    "    ocr_lines = open(ocr_path).readlines()\n",
    "    ocr_lines = ocr_nas_remove_page(ocr_lines)\n",
    "    gt_str = refine_lines(gt_lines)\n",
    "    ocr_str =  refine_lines(ocr_lines)\n",
    "    return gt_str, ocr_str\n",
    "\n",
    "def get_similarity(gt_str, ocr_str):\n",
    "    similarity = {\n",
    "        '~case_word': word_similarity(gt_str, ocr_str),\n",
    "        'case_word': word_similarity(gt_str, ocr_str, case_sensitive=True),\n",
    "        '~case_char': char_similarity(gt_str, ocr_str),\n",
    "        'case_char': char_similarity(gt_str, ocr_str, case_sensitive= True)\n",
    "    }\n",
    "    return similarity\n",
    "\n",
    "def evaluate_quality(gt_dir, ocr_dir):\n",
    "    gt_paths, ocr_paths = get_file_path(gt_dir, ocr_dir)\n",
    "    gt_fns, ocr_fns = get_file_names(gt_paths, ocr_paths)\n",
    "    paired_df = pair_paths(gt_paths, ocr_paths, gt_fns, ocr_fns)\n",
    "    similarities = []\n",
    "    for idx, fn, gt_path, ocr_path in paired_df.itertuples():\n",
    "        gt_str, ocr_str = get_str(gt_path, ocr_path)\n",
    "        similarity = get_similarity(gt_str, ocr_str)\n",
    "        similarity['fn'] = fn\n",
    "        similarities.append(similarity)\n",
    "    similarities = pd.DataFrame(similarities)\n",
    "    return similarities\n",
    "\n",
    "\n",
    "similarities = evaluate_quality(TXT_CROWDSOURCE_DIR, TXT_OCR_NAS_DIR)\n",
    "print CNT_OCR_CLEAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case_char max = 1.0 mean = 0.920727261387\n",
      "( 0.7, 0.8] : 1 \n",
      "( 0.8, 0.9] : 21 \n",
      "( 0.9,0.95] : 64 \n",
      "(0.95,0.98] : 93 \n",
      "(0.98,0.99] : 29 \n",
      "(0.99, 1.1] : 29 \n",
      "\n",
      "\n",
      "~case_char max = 1.0 mean = 0.921705891622\n",
      "( 0.7, 0.8] : 1 \n",
      "( 0.8, 0.9] : 21 \n",
      "( 0.9,0.95] : 62 \n",
      "(0.95,0.98] : 93 \n",
      "(0.98,0.99] : 31 \n",
      "(0.99, 1.1] : 29 \n",
      "\n",
      "\n",
      "case_word max = 1.0 mean = 0.788253087506\n",
      "( 0.7, 0.8] : 59 \n",
      "( 0.8, 0.9] : 81 \n",
      "( 0.9,0.95] : 42 \n",
      "(0.95,0.98] : 16 \n",
      "(0.98,0.99] : 1 \n",
      "(0.99, 1.1] : 6 \n",
      "\n",
      "\n",
      "~case_word max = 1.0 mean = 0.789390955376\n",
      "( 0.7, 0.8] : 59 \n",
      "( 0.8, 0.9] : 79 \n",
      "( 0.9,0.95] : 44 \n",
      "(0.95,0.98] : 16 \n",
      "(0.98,0.99] : 1 \n",
      "(0.99, 1.1] : 6 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "def print_statistics(similarities, col):\n",
    "    array = similarities[col]\n",
    "    print col, 'max =', array.max(), 'mean =',array.mean()\n",
    "    ratio_lower = [0.7, 0.8, 0.9, 0.95, 0.98, 0.99]\n",
    "    ratio_upper = [0.8, 0.9, 0.95, 0.98, 0.99, 1.1]\n",
    "    for l,u in zip(ratio_lower,ratio_upper):\n",
    "        print '({:4},{:4}] : {} '.format(l,u, ((array>l)&(array<=u)).value_counts()[True])\n",
    "    print '\\n'\n",
    "print_statistics(similarities, 'case_char')\n",
    "print_statistics(similarities, '~case_char')\n",
    "print_statistics(similarities, 'case_word')\n",
    "print_statistics(similarities, '~case_word')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False    243\n",
      "True       5\n",
      "dtype: int64\n",
      "False    248\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# print (similarities['case_char']<similarities['~case_char']).value_counts()\n",
    "print (similarities['case_char']>similarities['~case_char']).value_counts()\n",
    "# print (similarities['case_word']<similarities['~case_word']).value_counts()\n",
    "print (similarities['case_word']>similarities['~case_word']).value_counts()\n",
    "# similarities[(similarities['case_ch']>similarities['~case_ch'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# single str test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['11-4-43', 'a-7-p389', 'riot', 'imai', 'asaichi', 'and', 'mrs.', 'kagawa:']"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(re.split'[ \\n]', '11-4-43 a-7-p389 riot\\nimai asaichi and mrs. kagawa:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11-4-43 A-7-P389 Riot\n",
      "IMAI ASAICHI and MRS. KAGAWA:\n",
      "Asaichi, chief cook, and Mrs. Kagawa, Assist.\n",
      "Chief Cook from #4 Mess Hall stated that:\n",
      "Hibino Yusaki - 4314-D\n",
      "Yahumoto Hyomen - 4302-E\n",
      "Nakamura Mobijiro - 4305-C\n",
      "were leaders of a group of 'muscle men' are the\n",
      "following names and addresses:\n",
      "Oki Kakuma - 4313C\n",
      "Marsui Takeo - 4306-A\n",
      "Yamasaki Mineiichi 4305-E\n",
      "Kumagai Kazao 430-1-E\n",
      "(over)\n",
      "11-4-43 A-7-$389 Bio t\n",
      "IMAI ASAICHI and MRS. KAGAWA;\n",
      "Asaichi, chief cook, and Mrs. Kagawa, Assist. s\n",
      "Chief Cook from #4 Mess Hall stited that:\n",
      "Hihino Yusaki-- 4314-D\n",
      "Yahumoto Hyomeh - 4302-E\n",
      "Nakarjura Mohijiro - 4305-C\n",
      "were leaders of a group of 'muscle men' are the\n",
      "following names and addresses:\n",
      "Oki Kakuma - 4313C\n",
      "Marsui Tpkeo - 4306-A\n",
      "Yamasaki Mineiichi 4305-E\n",
      "Kumagai Kazao 430-1 -E (over)\n",
      "\n",
      "11-4-43 a-7-p389 riot\n",
      "imai asaichi and mrs. kagawa:\n",
      "asaichi, chief cook, and mrs. kagawa, assist.\n",
      "chief cook from #4 mess hall stated that:\n",
      "hibino yusaki - 4314-d\n",
      "yahumoto hyomen - 4302-e\n",
      "nakamura mobijiro - 4305-c\n",
      "were leaders of a group of 'muscle men' are the\n",
      "following names and addresses:\n",
      "oki kakuma - 4313c\n",
      "marsui takeo - 4306-a\n",
      "yamasaki mineiichi 4305-e\n",
      "kumagai kazao 430-1-e\n",
      "(over)\n",
      "11-4-43 a-7-$389 bio t\n",
      "imai asaichi and mrs. kagawa;\n",
      "asaichi, chief cook, and mrs. kagawa, assist. s\n",
      "chief cook from #4 mess hall stited that:\n",
      "hihino yusaki-- 4314-d\n",
      "yahumoto hyomeh - 4302-e\n",
      "nakarjura mohijiro - 4305-c\n",
      "were leaders of a group of 'muscle men' are the\n",
      "following names and addresses:\n",
      "oki kakuma - 4313c\n",
      "marsui tpkeo - 4306-a\n",
      "yamasaki mineiichi 4305-e\n",
      "kumagai kazao 430-1 -e (over)\n",
      "389 394 389 394\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'case_char': 0.9655172413793104,\n",
       " 'case_word': 0.8,\n",
       " '~case_char': 0.9655172413793104,\n",
       " '~case_word': 0.8}"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_diff(diff):\n",
    "    diff = list(diff)\n",
    "    same = 0\n",
    "    total = 0\n",
    "    for d in diff:\n",
    "        total+=1\n",
    "        if d.startswith((' ')):\n",
    "            same+=1\n",
    "    print same,'/',total\n",
    "\n",
    "def wordize(s):\n",
    "    return re.split('[ \\n]', s)\n",
    "\n",
    "\n",
    "def word_similarity(seq1, seq2, case_sensitive=False):\n",
    "    assert type(seq1)==str, 'seq1 is not a string'\n",
    "    assert type(seq2)==str, 'seq2 is not a string'\n",
    "    if not case_sensitive:\n",
    "        seq1, seq2 = seq1.lower(), seq2.lower()\n",
    "    return cal_similarity(wordize(seq1), wordize(seq2))\n",
    "def get_similarity(gt_str, ocr_str):\n",
    "    similarity = {\n",
    "        '~case_word': word_similarity(gt_str, ocr_str),\n",
    "        'case_word': word_similarity(gt_str, ocr_str, case_sensitive=True),\n",
    "        '~case_char': char_similarity(gt_str, ocr_str),\n",
    "        'case_char': char_similarity(gt_str, ocr_str, case_sensitive= True)\n",
    "    }\n",
    "    return similarity\n",
    "\n",
    "def evaluate_quality_one(gt_dir, ocr_dir, fn):\n",
    "    gt_path = gt_dir+fn\n",
    "    ocr_path = ocr_dir+fn\n",
    "    gt_str, ocr_str = get_str(gt_path, ocr_path)\n",
    "    print gt_str\n",
    "    print ocr_str\n",
    "    print \n",
    "    print gt_str.lower()\n",
    "    print ocr_str.lower()\n",
    "    print len(gt_str), len(ocr_str), len(gt_str.lower()), len(ocr_str.lower())\n",
    "    similarity = get_similarity(gt_str, ocr_str)\n",
    "    return similarity\n",
    "\n",
    "box_dir = 'Box8-TULE LAKE/'\n",
    "no = '0759'\n",
    "# no = '0270'\n",
    "fn = box_dir+'Box8-MINIDOKA to TULE LAKE-%s.txt' % no\n",
    "evaluate_quality_one(TXT_CROWDSOURCE_DIR, TXT_OCR_NAS_DIR, fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The strings are the same (case insensitive)\n"
     ]
    }
   ],
   "source": [
    "string1 = 'Hello'\n",
    "string2 = 'hello'\n",
    "\n",
    "if string1.lower() == string2.lower():\n",
    "    print \"The strings are the same (case insensitive)\"\n",
    "else:\n",
    "    print \"The strings are not the same (case insensitive)\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    " \n",
    "box_dir = 'Box8-TULE LAKE/'\n",
    "no = '0759'\n",
    "no = '0664'\n",
    "# no = '0270'\n",
    "# no = '0269'\n",
    "fn = box_dir+'Box8-MINIDOKA to TULE LAKE-%s.txt' % no\n",
    "gt_lines = list(open(TXT_CROWDSOURCE_DIR+fn).readlines())\n",
    "ocr_lines = list(open(TXT_OCR_NAS_DIR+fn).readlines())[2:]\n",
    "# gt_str= ''.join(gt_lines)\n",
    "# ocr_str=''.join(ocr_lines)\n",
    "gt_str = refine_lines(gt_lines)\n",
    "ocr_str = refine_lines(ocr_lines)\n",
    "gt_str_lower = gt_str.lower()\n",
    "ocr_str_lower = ocr_str.lower()\n",
    "gt_str_lower_m =manually_lower(gt_str)\n",
    "ocr_str_lower_m  = manually_lower(ocr_str)\n",
    "gt_str_decode = gt_str.decode('utf-8')\n",
    "ocr_str_decode = ocr_str.decode('utf-8')\n",
    "gt_str_decode_lower = gt_str.decode('utf-8').lower()\n",
    "ocr_str_decode_lower = ocr_str.decode('utf-8').lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('3/7/44 A-172 INFRACTIONS OFPROJECT REGULATIONSARASUNA, Teruois a janitor at Japanese language school.',\n",
       " 'Teruoft* a jftnttcr at ^ptcael*j!g\\xc2\\xbb?\\xc2\\xa3\\xc2\\xa9')"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_str, ocr_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('3/7/44 a-172 infractions ofproject regulationsarasuna, teruois a janitor at japanese language school.',\n",
       " 'teruoft* a jftnttcr at ^ptcael*j!g\\xc2\\xbb?\\xc2\\xa3\\xc2\\xa9')"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_str_lower, ocr_str_lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "376"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_str.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "376"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_str_lower.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.28169014084507044, 0.28776978417266186)"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cal_similarity(gt_str, ocr_str), cal_similarity(gt_str_decode, ocr_str_decode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.2535211267605634, 0.28776978417266186)"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cal_similarity(ocr_str, gt_str), cal_similarity(gt_str_decode, ocr_str_decode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.2589928057553957, 0.2535211267605634, 0.2535211267605634)"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cal_similarity(gt_str_decode_lower, ocr_str_decode_lower),\\\n",
    "cal_similarity(ocr_str_lower, gt_str_lower),\\\n",
    "cal_similarity(gt_str_lower_m, ocr_str_lower_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55 5 Teruo\n",
      "0 5 Teruo\n",
      "62 4  a j\n",
      "8 4  a j\n",
      "67 1 n\n",
      "14 1 n\n",
      "69 1 t\n",
      "15 1 t\n",
      "71 5 r at \n",
      "18 5 r at \n",
      "77 1 a\n",
      "27 1 a\n",
      "81 1 e\n",
      "28 1 e\n",
      "85 1 l\n",
      "29 1 l\n",
      "88 1 g\n",
      "33 1 g\n",
      "101 0 \n",
      "41 0 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'apanese la'"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from difflib import SequenceMatcher\n",
    "\n",
    "s = SequenceMatcher(None, gt_str, ocr_str)\n",
    "s.get_matching_blocks()\n",
    "for match in s.get_matching_blocks():\n",
    "    print match.a, match.size, gt_str[match.a:match.a+match.size]\n",
    "    print match.b, match.size, ocr_str[match.b:match.b+match.size]\n",
    "gt_str[77:87]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Match(a=55, b=0, size=5), Match(a=62, b=8, size=4), Match(a=67, b=14, size=1), Match(a=69, b=15, size=1), Match(a=71, b=18, size=5), Match(a=76, b=31, size=1), Match(a=88, b=33, size=1), Match(a=101, b=41, size=0)]\n",
      "55 5 teruo\n",
      "0 5 teruo\n",
      "62 4  a j\n",
      "8 4  a j\n",
      "67 1 n\n",
      "14 1 n\n",
      "69 1 t\n",
      "15 1 t\n",
      "71 5 r at \n",
      "18 5 r at \n",
      "76 1 j\n",
      "31 1 j\n",
      "88 1 g\n",
      "33 1 g\n",
      "101 0 \n",
      "41 0 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('japanese l', 'j!g\\xc2\\xbb?\\xc2\\xa3\\xc2\\xa9')"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = SequenceMatcher(None, gt_str_lower, ocr_str_lower)\n",
    "print s.get_matching_blocks()\n",
    "for match in s.get_matching_blocks():\n",
    "    print match.a, match.size, gt_str_lower[match.a:match.a+match.size]\n",
    "    print match.b, match.size, ocr_str_lower[match.b:match.b+match.size]\n",
    "gt_str_lower[76:86], ocr_str_lower[31:]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
